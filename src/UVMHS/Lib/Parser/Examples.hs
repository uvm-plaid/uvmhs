module UVMHS.Lib.Parser.Examples where

import UVMHS.Core
import UVMHS.Lib.Pretty
import UVMHS.Lib.Parser.Core
import UVMHS.Lib.Parser.ParserInput
import UVMHS.Lib.Parser.Regex
import UVMHS.Lib.Parser.CParser

testParsingSmall ‚à∑ IO ()
testParsingSmall = parseIOMain parser "<small example>" input
  where
    parser = cpWord $ ùï§ "xyzxyz"
    input = tokens "xyzxycxyz"

testParsingMultiline ‚à∑ IO ()
testParsingMultiline = parseIOMain parser "<multiline example>" input
  where
    parser = exec $ inbetween (void $ cpWord $ ùï§ "\n") $ list $ replicateI (ùïü 7) $ \ n ‚Üí cpNewContext "line" $ void $ cpWord ("xyz" ‚ß∫ showùïä n)
    input = tokens "xyz0\nxyz1\nxyz2\nxyc3\nxyz4\nxyz5\nxyz6\n"

testParsingBranching ‚à∑ IO ()
testParsingBranching = parseIOMain parser "<branching example>" input
  where
    parser ‚à∑ CParser ‚ÑÇ ùïä
    parser = tries
      [ cpNewContext "XXX*" $ tries
          [ cpRender (formats [FG pink]) $ cpWord "xxxy"
          , cpRender (formats [FG pink]) $ cpWord "xxxz"
          ]
      , cpNewContext "XXXZ" $ do
          x ‚Üê cpErr "XX" $ cpRender (formats [FG blue]) $ cpWord "xx"
          y ‚Üê cpErr "XZ" $ cpRender (formats [FG green]) $ cpWord "xz"
          return $ x ‚ß∫ y
      , cpNewContext "XXZZ" $ cpWord "xxzz"
      , cpNewContext "XXXAorB" $ cpRender (formats [FG teal]) $ do
          x ‚Üê cpWord "xxx"
          y ‚Üê single ^$ tries
            [ cpToken 'a'
            , cpToken 'b'
            ]
          return $ x ‚ß∫ y
      ]
    input ‚à∑ ùïç (ParserToken ‚ÑÇ)
    input = tokens "xxxx"

-- testParsingAmbiguity ‚à∑ IO ()
-- testParsingAmbiguity = parseIOMain parser input
--   where
--     parser = concat ^$ pOneOrMore $ tries
--       [ ppFG yellow ‚àò ppString ‚àò single ^$ pToken 'y'
--       , ppFG green ‚àò ppString ‚àò single ^$ pToken 'x'
--       , ppFG blue ‚àò ppString ^$ pWord "xx"
--       ]
--     input = tokens "xxx"

testParsingGreedy ‚à∑ IO ()
testParsingGreedy = parseIOMain parser "<greedy example>" input
  where
    parser = concat ^$ cpOneOrMore $ tries
      [ ppFG yellow ‚àò ppString ‚àò single ^$ cpRender (formats [FG yellow]) $ toCParser $ rpToken 'y'
      , ppFG green ‚àò ppString ‚àò single ^$ cpRender (formats [FG green]) $ toCParser $ rpToken 'x'
      , ppFG blue ‚àò ppString ^$ cpRender (formats [FG yellow]) $ cpWord "xx"
      ]
    input = tokens "xxx"

testParsingGreedyAmbiguity ‚à∑ IO ()
testParsingGreedyAmbiguity = parseIOMain parser "<greedy ambiguity example>" input
  where
    parser = concat ^$ cpOneOrMore $ tries
      [ ppFG yellow ‚àò ppString ‚àò single ^$ cpRender (formats [FG yellow]) $ toCParser $ rpToken 'y'
      , tries
          [ ppFG blue ‚àò ppString ^$ cpRender (formats [FG blue]) $ cpWord "x"
          , ppFG pink ‚àò ppString ^$ cpRender (formats [FG pink]) $ cpWord "xx"
          ]
      , ppFG green ‚àò ppString ‚àò single ^$ cpRender (formats [FG green]) $ toCParser $ rpToken 'x'
      ]
    input = tokens "xxx"

testParsingSuccess ‚à∑ IO ()
testParsingSuccess = parseIOMain parser "<success example>" input
  where
    parser = concat ^$ cpOneOrMore $ tries
      [ cpRender (formats [FG green]) $ cpWord $ ùï§ "xx"
      , cpRender (formats [FG blue]) $ cpWord $ ùï§ "yy"
      ]
    input = tokens "xxxxyyxxyy"

testParsingErrorNewline ‚à∑ IO ()
testParsingErrorNewline = parseIOMain (string ^$ cpMany $ toCParser $ rpToken 'x') "<error newline example>" $ tokens "xxx\nx"

testParsingErrorEof ‚à∑ IO ()
testParsingErrorEof = parseIOMain (exec $ replicate (ùïü 3) $ void $ cpToken 'x') "<error eof example>" $ tokens "xx"

testTokenizeSimple ‚à∑ IO ()
testTokenizeSimple =
  let rgx = lWord "x" ‚ñ∑ oepsRegex ()
      dfa = compileRegex rgx
  in tokenizeIOMain (Lexer (const dfa) (const ‚àò ((:*) False) ‚àò string) ()) "<tokenize simple example>" $ tokens "xxx"

testTokenize ‚à∑ IO ()
testTokenize =
  let rgx = concat [lWord "x",lWord "xy",lWord "y"] ‚ñ∑ oepsRegex ()
      dfa = compileRegex rgx
  in tokenizeIOMain (Lexer (const dfa) (const ‚àò ((:*) False) ‚àò string) ()) "<tokenize example>" $ tokens "xxyxyxyxyxxyy"

testTokenizeFailure1 ‚à∑ IO ()
testTokenizeFailure1 =
  let rgx = concat
        [ lWord "x" ‚ñ∑ fepsRegex (formats [FG green]) ‚ñ∑ lepsRegex (ùïü64 2)
        , lWord "x" ‚ñ∑ fepsRegex (formats [FG yellow]) ‚ñ∑ lepsRegex (ùïü64 1)
        , lWord "xx" ‚ñ∑ fepsRegex (formats [FG blue])
        , lWord "xy" ‚ñ∑ fepsRegex (formats [FG teal])
        , lWord "xz" ‚ñ∑ fepsRegex (formats [FG pink])
        ] ‚ñ∑ oepsRegex ()
      dfa = compileRegex rgx
  in tokenizeIOMain (Lexer (const dfa) (const ‚àò ((:*) False) ‚àò string) ()) "<tokenize failure1 example>" $ tokens "xxxxy"

testTokenizeFailure2 ‚à∑ IO ()
testTokenizeFailure2 =
  let rgx = concat
        [ lWord "x" ‚ñ∑ fepsRegex (formats [FG green]) ‚ñ∑ lepsRegex (ùïü64 2)
        , lWord "x" ‚ñ∑ fepsRegex (formats [FG yellow]) ‚ñ∑ lepsRegex (ùïü64 1)
        , lWord "xx" ‚ñ∑ fepsRegex (formats [FG blue])
        , lWord "xy" ‚ñ∑ fepsRegex (formats [FG teal])
        , lWord "xz" ‚ñ∑ fepsRegex (formats [FG pink])
        ] ‚ñ∑ oepsRegex ()
      dfa = compileRegex rgx
  in tokenizeIOMain (Lexer (const dfa) (const ‚àò ((:*) False) ‚àò string) ()) "<tokenize failiure2 example>" $ tokens "xxxyxxxzxc"

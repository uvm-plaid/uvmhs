module UVMHS.Lib.Parser.Examples where

import UVMHS.Core
import UVMHS.Lib.Parser.GenParser
import UVMHS.Lib.Parser.GenLexer
import UVMHS.Lib.Parser.ParserInput
import UVMHS.Lib.Parser.RawParser
import UVMHS.Lib.Parser.Regex
import UVMHS.Lib.Parser.StdParser
import UVMHS.Lib.Pretty

testParsingSmall ‚à∑ IO ()
testParsingSmall = gparseIOMain parser "<small example>" input
  where
    parser = gpWord $ ùï§ "xyzxyz"
    input = tokens "xyzxycxyz"

testParsingMultiline ‚à∑ IO ()
testParsingMultiline = gparseIOMain parser "<multiline example>" input
  where
    parser = exec $ inbetween (gpWord $ ùï§ "\n") $ list $ replicateI (ùïü 7) $ \ n ‚Üí gpNewContext "line" $ gpWord ("xyz" ‚ß∫ showùïä n)
    input = tokens "xyz0\nxyz1\nxyz2\nxyc3\nxyz4\nxyz5\nxyz6\n"

testParsingBranching ‚à∑ IO ()
testParsingBranching = gparseIOMain parser "<branching example>" input
  where
    parser ‚à∑ GenParser ‚ÑÇ ùïä
    parser = tries
      [ gpNewContext "XXX*" $ tries
          [ gpRender (formats [FG pink]) $ gpWordRet "xxxy"
          , gpRender (formats [FG pink]) $ gpWordRet "xxxz"
          ]
      , gpNewContext "XXXZ" $ do
          x ‚Üê gpErr "XX" $ gpRender (formats [FG blue]) $ gpWordRet "xx"
          y ‚Üê gpErr "XZ" $ gpRender (formats [FG green]) $ gpWordRet "xz"
          return $ x ‚ß∫ y
      , gpNewContext "XXZZ" $ gpWordRet "xxzz"
      , gpNewContext "XXXAorB" $ gpRender (formats [FG teal]) $ do
          x ‚Üê gpWordRet "xxx"
          y ‚Üê single ^$ tries
            [ gpTokRet 'a'
            , gpTokRet 'b'
            ]
          return $ x ‚ß∫ y
      ]
    input ‚à∑ ùïç (ParserToken ‚ÑÇ)
    input = tokens "xxxx"

-- testParsingAmbiguity ‚à∑ IO ()
-- testParsingAmbiguity = gparseIOMain parser input
--   where
--     parser = concat ^$ oneOrMore $ tries
--       [ ppFG yellow ‚àò ppString ‚àò single ^$ gpTok 'y'
--       , ppFG green ‚àò ppString ‚àò single ^$ gpTok 'x'
--       , ppFG blue ‚àò ppString ^$ gpWord "xx"
--       ]
--     input = tokens "xxx"

testParsingGreedy ‚à∑ IO ()
testParsingGreedy = gparseIOMain parser "<greedy example>" input
  where
    parser = concat ^$ oneOrMore $ tries
      [ ppFG yellow ‚àò ppString ‚àò single ^$ gpRender (formats [FG yellow]) $ gpRawParser $ rpToken 'y'
      , ppFG green ‚àò ppString ‚àò single ^$ gpRender (formats [FG green]) $ gpRawParser $ rpToken 'x'
      , ppFG blue ‚àò ppString ^$ gpRender (formats [FG yellow]) $ gpWordRet "xx"
      ]
    input = tokens "xxx"

testParsingGreedyAmbiguity ‚à∑ IO ()
testParsingGreedyAmbiguity = gparseIOMain parser "<greedy ambiguity example>" input
  where
    parser = concat ^$ oneOrMore $ tries
      [ ppFG yellow ‚àò ppString ‚àò single ^$ gpRender (formats [FG yellow]) $ gpRawParser $ rpToken 'y'
      , tries
          [ ppFG blue ‚àò ppString ^$ gpRender (formats [FG blue]) $ gpWordRet "x"
          , ppFG pink ‚àò ppString ^$ gpRender (formats [FG pink]) $ gpWordRet "xx"
          ]
      , ppFG green ‚àò ppString ‚àò single ^$ gpRender (formats [FG green]) $ gpRawParser $ rpToken 'x'
      ]
    input = tokens "xxx"

testParsingSuccess ‚à∑ IO ()
testParsingSuccess = gparseIOMain parser "<success example>" input
  where
    parser = concat ^$ oneOrMore $ tries
      [ gpRender (formats [FG green]) $ gpWord $ ùï§ "xx"
      , gpRender (formats [FG blue]) $ gpWord $ ùï§ "yy"
      ]
    input = tokens "xxxxyyxxyy"

testParsingErrorNewline ‚à∑ IO ()
testParsingErrorNewline = gparseIOMain (string ^$ many $ gpRawParser $ rpToken 'x') "<error newline example>" $ tokens "xxx\nx"

testParsingErrorEof ‚à∑ IO ()
testParsingErrorEof = gparseIOMain (exec $ replicate (ùïü 3) $ gpTok 'x') "<error eof example>" $ tokens "xx"

testTokenizeSimple ‚à∑ IO ()
testTokenizeSimple =
  let rgx = lWord "x" ‚ñ∑ oepsRegex ()
      dfa = compileRegex rgx
  in glexIOMain (GenLexer (const dfa) (const ‚àò ((:*) False) ‚àò string) ()) "<tokenize simple example>" $ tokens "xxx"

testTokenize ‚à∑ IO ()
testTokenize =
  let rgx = concat [lWord "x",lWord "xy",lWord "y"] ‚ñ∑ oepsRegex ()
      dfa = compileRegex rgx
  in glexIOMain (GenLexer (const dfa) (const ‚àò ((:*) False) ‚àò string) ()) "<tokenize example>" $ tokens "xxyxyxyxyxxyy"

testTokenizeFailure1 ‚à∑ IO ()
testTokenizeFailure1 =
  let rgx = concat
        [ lWord "x" ‚ñ∑ fepsRegex (formats [FG green]) ‚ñ∑ lepsRegex (ùïü64 2)
        , lWord "x" ‚ñ∑ fepsRegex (formats [FG yellow]) ‚ñ∑ lepsRegex (ùïü64 1)
        , lWord "xx" ‚ñ∑ fepsRegex (formats [FG blue])
        , lWord "xy" ‚ñ∑ fepsRegex (formats [FG teal])
        , lWord "xz" ‚ñ∑ fepsRegex (formats [FG pink])
        ] ‚ñ∑ oepsRegex ()
      dfa = compileRegex rgx
  in glexIOMain (GenLexer (const dfa) (const ‚àò ((:*) False) ‚àò string) ()) "<tokenize failure1 example>" $ tokens "xxxxy"

testTokenizeFailure2 ‚à∑ IO ()
testTokenizeFailure2 =
  let rgx = concat
        [ lWord "x" ‚ñ∑ fepsRegex (formats [FG green]) ‚ñ∑ lepsRegex (ùïü64 2)
        , lWord "x" ‚ñ∑ fepsRegex (formats [FG yellow]) ‚ñ∑ lepsRegex (ùïü64 1)
        , lWord "xx" ‚ñ∑ fepsRegex (formats [FG blue])
        , lWord "xy" ‚ñ∑ fepsRegex (formats [FG teal])
        , lWord "xz" ‚ñ∑ fepsRegex (formats [FG pink])
        ] ‚ñ∑ oepsRegex ()
      dfa = compileRegex rgx
  in glexIOMain (GenLexer (const dfa) (const ‚àò ((:*) False) ‚àò string) ()) "<tokenize failiure2 example>" $ tokens "xxxyxxxzxc"

module UVMHS.Lib.Parser.Examples where

import UVMHS.Core
import UVMHS.Lib.Parser.Parser
import UVMHS.Lib.Parser.ParserInput
import UVMHS.Lib.Parser.RawParser
import UVMHS.Lib.Parser.Regex
import UVMHS.Lib.Pretty

testParsingSmall âˆ· IO ()
testParsingSmall = parseIOMain parser "<small example>" input
  where
    parser = pWord $ ğ•¤ "xyzxyz"
    input = tokens "xyzxycxyz"

testParsingMultiline âˆ· IO ()
testParsingMultiline = parseIOMain parser "<multiline example>" input
  where
    parser = exec $ inbetween (pWord $ ğ•¤ "\n") $ list $ replicateI (ğ•Ÿ 7) $ \ n â†’ pNewContext "line" $ pWord ("xyz" â§º showğ•Š n)
    input = tokens "xyz0\nxyz1\nxyz2\nxyc3\nxyz4\nxyz5\nxyz6\n"

testParsingBranching âˆ· IO ()
testParsingBranching = parseIOMain parser "<branching example>" input
  where
    parser âˆ· Parser â„‚ ğ•Š
    parser = tries
      [ pNewContext "XXX*" $ tries
          [ pRender (formats [FG pink]) $ pWordRet "xxxy"
          , pRender (formats [FG pink]) $ pWordRet "xxxz"
          ]
      , pNewContext "XXXZ" $ do
          x â† pErr "XX" $ pRender (formats [FG blue]) $ pWordRet "xx"
          y â† pErr "XZ" $ pRender (formats [FG green]) $ pWordRet "xz"
          return $ x â§º y
      , pNewContext "XXZZ" $ pWordRet "xxzz"
      , pNewContext "XXXAorB" $ pRender (formats [FG teal]) $ do
          x â† pWordRet "xxx"
          y â† single ^$ tries
            [ pTokRet 'a'
            , pTokRet 'b'
            ]
          return $ x â§º y
      ]
    input âˆ· ğ• (ParserToken â„‚)
    input = tokens "xxxx"

-- testParsingAmbiguity âˆ· IO ()
-- testParsingAmbiguity = parseIOMain parser input
--   where
--     parser = concat ^$ pOneOrMore $ tries
--       [ ppFG yellow âˆ˜ ppString âˆ˜ single ^$ pTok 'y'
--       , ppFG green âˆ˜ ppString âˆ˜ single ^$ pTok 'x'
--       , ppFG blue âˆ˜ ppString ^$ pWord "xx"
--       ]
--     input = tokens "xxx"

testParsingGreedy âˆ· IO ()
testParsingGreedy = parseIOMain parser "<greedy example>" input
  where
    parser = concat ^$ pOneOrMore $ tries
      [ ppFG yellow âˆ˜ ppString âˆ˜ single ^$ pRender (formats [FG yellow]) $ rawToParser $ rpToken 'y'
      , ppFG green âˆ˜ ppString âˆ˜ single ^$ pRender (formats [FG green]) $ rawToParser $ rpToken 'x'
      , ppFG blue âˆ˜ ppString ^$ pRender (formats [FG yellow]) $ pWordRet "xx"
      ]
    input = tokens "xxx"

testParsingGreedyAmbiguity âˆ· IO ()
testParsingGreedyAmbiguity = parseIOMain parser "<greedy ambiguity example>" input
  where
    parser = concat ^$ pOneOrMore $ tries
      [ ppFG yellow âˆ˜ ppString âˆ˜ single ^$ pRender (formats [FG yellow]) $ rawToParser $ rpToken 'y'
      , tries
          [ ppFG blue âˆ˜ ppString ^$ pRender (formats [FG blue]) $ pWordRet "x"
          , ppFG pink âˆ˜ ppString ^$ pRender (formats [FG pink]) $ pWordRet "xx"
          ]
      , ppFG green âˆ˜ ppString âˆ˜ single ^$ pRender (formats [FG green]) $ rawToParser $ rpToken 'x'
      ]
    input = tokens "xxx"

testParsingSuccess âˆ· IO ()
testParsingSuccess = parseIOMain parser "<success example>" input
  where
    parser = concat ^$ pOneOrMore $ tries
      [ pRender (formats [FG green]) $ pWord $ ğ•¤ "xx"
      , pRender (formats [FG blue]) $ pWord $ ğ•¤ "yy"
      ]
    input = tokens "xxxxyyxxyy"

testParsingErrorNewline âˆ· IO ()
testParsingErrorNewline = parseIOMain (string ^$ pMany $ rawToParser $ rpToken 'x') "<error newline example>" $ tokens "xxx\nx"

testParsingErrorEof âˆ· IO ()
testParsingErrorEof = parseIOMain (exec $ replicate (ğ•Ÿ 3) $ pTok 'x') "<error eof example>" $ tokens "xx"

testTokenizeSimple âˆ· IO ()
testTokenizeSimple =
  let rgx = lWord "x" â–· oepsRegex ()
      dfa = compileRegex rgx
  in tokenizeIOMain (Lexer (const dfa) (const âˆ˜ ((:*) False) âˆ˜ string) ()) "<tokenize simple example>" $ tokens "xxx"

testTokenize âˆ· IO ()
testTokenize =
  let rgx = concat [lWord "x",lWord "xy",lWord "y"] â–· oepsRegex ()
      dfa = compileRegex rgx
  in tokenizeIOMain (Lexer (const dfa) (const âˆ˜ ((:*) False) âˆ˜ string) ()) "<tokenize example>" $ tokens "xxyxyxyxyxxyy"

testTokenizeFailure1 âˆ· IO ()
testTokenizeFailure1 =
  let rgx = concat
        [ lWord "x" â–· fepsRegex (formats [FG green]) â–· lepsRegex (ğ•Ÿ64 2)
        , lWord "x" â–· fepsRegex (formats [FG yellow]) â–· lepsRegex (ğ•Ÿ64 1)
        , lWord "xx" â–· fepsRegex (formats [FG blue])
        , lWord "xy" â–· fepsRegex (formats [FG teal])
        , lWord "xz" â–· fepsRegex (formats [FG pink])
        ] â–· oepsRegex ()
      dfa = compileRegex rgx
  in tokenizeIOMain (Lexer (const dfa) (const âˆ˜ ((:*) False) âˆ˜ string) ()) "<tokenize failure1 example>" $ tokens "xxxxy"

testTokenizeFailure2 âˆ· IO ()
testTokenizeFailure2 =
  let rgx = concat
        [ lWord "x" â–· fepsRegex (formats [FG green]) â–· lepsRegex (ğ•Ÿ64 2)
        , lWord "x" â–· fepsRegex (formats [FG yellow]) â–· lepsRegex (ğ•Ÿ64 1)
        , lWord "xx" â–· fepsRegex (formats [FG blue])
        , lWord "xy" â–· fepsRegex (formats [FG teal])
        , lWord "xz" â–· fepsRegex (formats [FG pink])
        ] â–· oepsRegex ()
      dfa = compileRegex rgx
  in tokenizeIOMain (Lexer (const dfa) (const âˆ˜ ((:*) False) âˆ˜ string) ()) "<tokenize failiure2 example>" $ tokens "xxxyxxxzxc"

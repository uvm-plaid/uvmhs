module UVMHS.Lib.Parser.Examples where

import UVMHS.Core
import UVMHS.Lib.Pretty
import UVMHS.Lib.Parser.Core
import UVMHS.Lib.Parser.ParserInput
import UVMHS.Lib.Parser.Regex
import UVMHS.Lib.Parser.CParser

testParsingSmall âˆ· IO ()
testParsingSmall = parseIOMain parser "<small example>" input
  where
    parser = cpWord $ ğ•¤ "xyzxyz"
    input = tokens "xyzxycxyz"

testParsingMultiline âˆ· IO ()
testParsingMultiline = parseIOMain parser "<multiline example>" input
  where
    parser = exec $ inbetween (void $ cpWord $ ğ•¤ "\n") $ list $ replicateI (ğ•Ÿ 7) $ \ n â†’ cpNewContext "line" $ void $ cpWord ("xyz" â§º showğ•Š n)
    input = tokens "xyz0\nxyz1\nxyz2\nxyc3\nxyz4\nxyz5\nxyz6\n"

testParsingBranching âˆ· IO ()
testParsingBranching = parseIOMain parser "<branching example>" input
  where
    parser âˆ· CParser â„‚ ğ•Š
    parser = tries
      [ cpNewContext "XXX*" $ tries
          [ cpRender (formats [FG pink]) $ cpWord "xxxy"
          , cpRender (formats [FG pink]) $ cpWord "xxxz"
          ]
      , cpNewContext "XXXZ" $ do
          x â† cpErr "XX" $ cpRender (formats [FG blue]) $ cpWord "xx"
          y â† cpErr "XZ" $ cpRender (formats [FG green]) $ cpWord "xz"
          return $ x â§º y
      , cpNewContext "XXZZ" $ cpWord "xxzz"
      , cpNewContext "XXXAorB" $ cpRender (formats [FG teal]) $ do
          x â† cpWord "xxx"
          y â† single ^$ tries
            [ cpToken 'a'
            , cpToken 'b'
            ]
          return $ x â§º y
      ]
    input âˆ· ğ• (ParserToken â„‚)
    input = tokens "xxxx"

-- testParsingAmbiguity âˆ· IO ()
-- testParsingAmbiguity = parseIOMain parser input
--   where
--     parser = concat ^$ pOneOrMore $ tries
--       [ ppFG yellow âˆ˜ ppString âˆ˜ single ^$ pToken 'y'
--       , ppFG green âˆ˜ ppString âˆ˜ single ^$ pToken 'x'
--       , ppFG blue âˆ˜ ppString ^$ pWord "xx"
--       ]
--     input = tokens "xxx"

testParsingGreedy âˆ· IO ()
testParsingGreedy = parseIOMain parser "<greedy example>" input
  where
    parser = concat ^$ cpOneOrMore $ tries
      [ ppFG yellow âˆ˜ ppString âˆ˜ single ^$ cpRender (formats [FG yellow]) $ toCParser $ pToken 'y'
      , ppFG green âˆ˜ ppString âˆ˜ single ^$ cpRender (formats [FG green]) $ toCParser $ pToken 'x'
      , ppFG blue âˆ˜ ppString ^$ cpRender (formats [FG yellow]) $ cpWord "xx"
      ]
    input = tokens "xxx"

testParsingGreedyAmbiguity âˆ· IO ()
testParsingGreedyAmbiguity = parseIOMain parser "<greedy ambiguity example>" input
  where
    parser = concat ^$ cpOneOrMore $ tries
      [ ppFG yellow âˆ˜ ppString âˆ˜ single ^$ cpRender (formats [FG yellow]) $ toCParser $ pToken 'y'
      , tries
          [ ppFG blue âˆ˜ ppString ^$ cpRender (formats [FG blue]) $ cpWord "x"
          , ppFG pink âˆ˜ ppString ^$ cpRender (formats [FG pink]) $ cpWord "xx"
          ]
      , ppFG green âˆ˜ ppString âˆ˜ single ^$ cpRender (formats [FG green]) $ toCParser $ pToken 'x'
      ]
    input = tokens "xxx"

testParsingSuccess âˆ· IO ()
testParsingSuccess = parseIOMain parser "<success example>" input
  where
    parser = concat ^$ cpOneOrMore $ tries
      [ cpRender (formats [FG green]) $ cpWord $ ğ•¤ "xx"
      , cpRender (formats [FG blue]) $ cpWord $ ğ•¤ "yy"
      ]
    input = tokens "xxxxyyxxyy"

testParsingErrorNewline âˆ· IO ()
testParsingErrorNewline = parseIOMain (string ^$ cpMany $ toCParser $ pToken 'x') "<error newline example>" $ tokens "xxx\nx"

testParsingErrorEof âˆ· IO ()
testParsingErrorEof = parseIOMain (exec $ replicate (ğ•Ÿ 3) $ void $ cpToken 'x') "<error eof example>" $ tokens "xx"

testTokenizeSimple âˆ· IO ()
testTokenizeSimple =
  let rgx = lWord "x" â–· oepsRegex ()
      dfa = compileRegex rgx
  in tokenizeIOMain (Lexer (const dfa) (const âˆ˜ ((:*) False) âˆ˜ string) ()) "<tokenize simple example>" $ tokens "xxx"

testTokenize âˆ· IO ()
testTokenize =
  let rgx = concat [lWord "x",lWord "xy",lWord "y"] â–· oepsRegex ()
      dfa = compileRegex rgx
  in tokenizeIOMain (Lexer (const dfa) (const âˆ˜ ((:*) False) âˆ˜ string) ()) "<tokenize example>" $ tokens "xxyxyxyxyxxyy"

testTokenizeFailure1 âˆ· IO ()
testTokenizeFailure1 =
  let rgx = concat
        [ lWord "x" â–· fepsRegex (formats [FG green]) â–· lepsRegex (ğ•Ÿ64 2)
        , lWord "x" â–· fepsRegex (formats [FG yellow]) â–· lepsRegex (ğ•Ÿ64 1)
        , lWord "xx" â–· fepsRegex (formats [FG blue])
        , lWord "xy" â–· fepsRegex (formats [FG teal])
        , lWord "xz" â–· fepsRegex (formats [FG pink])
        ] â–· oepsRegex ()
      dfa = compileRegex rgx
  in tokenizeIOMain (Lexer (const dfa) (const âˆ˜ ((:*) False) âˆ˜ string) ()) "<tokenize failure1 example>" $ tokens "xxxxy"

testTokenizeFailure2 âˆ· IO ()
testTokenizeFailure2 =
  let rgx = concat
        [ lWord "x" â–· fepsRegex (formats [FG green]) â–· lepsRegex (ğ•Ÿ64 2)
        , lWord "x" â–· fepsRegex (formats [FG yellow]) â–· lepsRegex (ğ•Ÿ64 1)
        , lWord "xx" â–· fepsRegex (formats [FG blue])
        , lWord "xy" â–· fepsRegex (formats [FG teal])
        , lWord "xz" â–· fepsRegex (formats [FG pink])
        ] â–· oepsRegex ()
      dfa = compileRegex rgx
  in tokenizeIOMain (Lexer (const dfa) (const âˆ˜ ((:*) False) âˆ˜ string) ()) "<tokenize failiure2 example>" $ tokens "xxxyxxxzxc"
